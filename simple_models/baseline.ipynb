{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58f6dc1-d42f-42d5-9814-4e0b4fe97169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb2d7ce-f3ba-4c16-8280-23f705040ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory\n",
    "sat_dir = os.path.expanduser('~/sea-level-seekers/iharp_training_dataset/Copernicus_ENA_Satelite_Maps_Training_Data')\n",
    "sat_names = os.listdir(sat_dir)\n",
    "flood_dir = os.path.expanduser('~/sea-level-seekers/iharp_training_dataset/Flooding_Data')\n",
    "flood_names = os.listdir(flood_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f33f10-3301-43be-ab20-ad263016ea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all file names with their full paths\n",
    "try:\n",
    "    sat_names = [os.path.join(sat_dir, f) for f in os.listdir(sat_dir)]\n",
    "    flood_names = [os.path.join(flood_dir, f) for f in os.listdir(flood_dir) if f.endswith('.csv')]\n",
    "except FileNotFoundError:\n",
    "    print(f\"Directory not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d055da8-d672-4f0b-bc08-993a7f46d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_extractor(filename):\n",
    "    file_name = filename\n",
    "    \n",
    "    # Regular expression to extract the date\n",
    "    match = re.search(r'dt_ena_(\\d+)_vDT', file_name)\n",
    "    date_str = match.group(1)  # '19930101'\n",
    "    \n",
    "    # Format the date as 'YYYY-MM-DD'\n",
    "    formatted_date = f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}\"\n",
    "    \n",
    "    return formatted_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966f4278-1320-4673-8db8-7e132c3f3e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all files in the directory\n",
    "for filename in sat_names:\n",
    "    # Extract the date part from the filename and format it\n",
    "    formatted_date = date_extractor(filename)\n",
    "\n",
    "    # Open the .nc file\n",
    "    dataset = netCDF4.Dataset(file_path, mode=\"r\")\n",
    "\n",
    "    # Extract the 'sla' variable\n",
    "    sla = dataset.variables[\"sla\"][:]\n",
    "\n",
    "    # Calculate the average of all values stored in sla\n",
    "    average_sla = np.mean(sla)\n",
    "\n",
    "    # Determine the value for the additional columns\n",
    "    value = 1 if average_sla >= 0 else 0\n",
    "\n",
    "    # Append the result to the list\n",
    "    results.append([formatted_date, average_sla] + [value] * 12)\n",
    "\n",
    "    # Close the dataset\n",
    "    dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b6c426-dae7-48b9-8ec6-1fea2c536cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the results\n",
    "columns = [\n",
    "    \"Date\",\n",
    "    \"Average_SLA\",\n",
    "    \"Atlantic City\",\n",
    "    \"Baltimore\",\n",
    "    \"Eastport\",\n",
    "    \"Fort Pulaski\",\n",
    "    \"Lewes\",\n",
    "    \"New London\",\n",
    "    \"Newport\",\n",
    "    \"Portland\",\n",
    "    \"Sandy Hook\",\n",
    "    \"Sewells Point\",\n",
    "    \"The Battery\",\n",
    "    \"Washington\",\n",
    "]\n",
    "results_df = pd.DataFrame(results, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebb3a64-3418-4083-b45b-0a34c25dab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the Average_SLA column\n",
    "results_df = results_df.drop(columns=[\"Average_SLA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159c0173-1f6d-4a98-96a1-c80fb9fc3cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_path = \"/home/jovyan/sea-level-seekers/simple_models/baseline.csv\"\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv(output_csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
